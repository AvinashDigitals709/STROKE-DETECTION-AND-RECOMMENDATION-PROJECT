{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Change to the desired directory\n",
        "os.chdir('/content/drive/MyDrive/Recommendations ')\n",
        "\n",
        "# Confirm the change\n",
        "print(\"Current Directory:\", os.getcwd())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGDmoPua5SFA",
        "outputId": "62312d23-58a5-43be-93d0-d817ce2b3178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Directory: /content/drive/MyDrive/Recommendations \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9qQzHSOASUCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Lcr3arHST7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7HtT9-ZGSTuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install required packages (if not installed)\n",
        "!pip install pandas scikit-learn\n",
        "\n",
        "# STEP 2: Imports\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "\n",
        "# STEP 3: Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Recommendations /Final stroke recommendations .csv\")  # Replace with your file path\n",
        "\n",
        "# STEP 4: Drop 'id' column if present\n",
        "if 'id' in df.columns:\n",
        "    df.drop(columns=['id'], inplace=True)\n",
        "\n",
        "# STEP 5: Drop missing data\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# STEP 6: Encode categorical columns\n",
        "label_encoders = {}\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # Store for later decoding\n",
        "\n",
        "# STEP 7: Define input (X) and output (Y) features\n",
        "X = df.drop(columns=['stroke_stage', 'stroke_type', 'recommended_doctor', 'medication', 'recommended_duration'])\n",
        "Y = df[['stroke_stage', 'stroke_type', 'recommended_doctor', 'medication', 'recommended_duration']]\n",
        "\n",
        "\n",
        "# STEP 8: Train/test split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 🔹 DEBUG: Print unique values in each output column before training\n",
        "for col in Y_train.columns:\n",
        "    print(f\"Unique labels in {col}:\", Y_train[col].unique())\n",
        "\n",
        "# STEP 9: Train model using RandomForest\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "multi_model = MultiOutputClassifier(rf)\n",
        "multi_model.fit(X_train, Y_train)\n",
        "\n",
        "# STEP 10: Save the trained model\n",
        "with open('final_stroke_recommendation_model.pkl', 'wb') as f:\n",
        "    pickle.dump(multi_model, f)\n",
        "\n",
        "# STEP 11: Save label encoders\n",
        "with open('final_label_encoders.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoders, f)\n",
        "\n",
        "# STEP 12: Save EVERYTHING in a single file\n",
        "with open('full_model.pkl', 'wb') as f:\n",
        "    pickle.dump({\"model\": multi_model, \"encoders\": label_encoders}, f)\n",
        "\n",
        "print(\"✅ Models saved: 'final_stroke_recommendation_model.pkl', 'final_label_encoders.pkl', and 'final_full_model.pkl'\")\n",
        "\n",
        "\n",
        "\n",
        "#updated code for recommendations and all with one model file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeDw6sEeRQU9",
        "outputId": "ae600c85-5afe-4bfe-d41f-a0ec409cac45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "✅ Models saved: 'final_stroke_recommendation_model.pkl', 'final_label_encoders.pkl', and 'final_full_model.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download CNN model\n",
        "files.download('/content/drive/MyDrive/Recommendations /final_stroke_recommendation_model.pkl')\n",
        "\n",
        "# Download recommendation model\n",
        "files.download('/content/drive/MyDrive/Recommendations /final_label_encoders.pkl')\n",
        "\n",
        "# Download label encoders (if used)\n",
        "files.download('/content/drive/MyDrive/Recommendations /full_model.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "uqmVBxwxSfQM",
        "outputId": "d6b46254-8ee8-4c60-e293-dc30d03b7875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cbcb4414-9198-4f9b-813f-0517a8550edc\", \"final_stroke_recommendation_model.pkl\", 17500749)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0e98b74b-c5f1-4098-8326-8ac113c08076\", \"final_label_encoders.pkl\", 1477)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_168f7df4-17bf-4a7e-8c8a-9c7fabf6e03c\", \"full_model.pkl\", 17502040)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7AbS00Kx6gFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZnfA1QnQ74X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mx_NuSuW-4dY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install required packages\n",
        "!pip install pandas scikit-learn --quiet\n",
        "\n",
        "# STEP 2: Imports\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# STEP 3: Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Recommendations /Final stroke recommendations .csv\")\n",
        "\n",
        "# STEP 4: Data Cleaning\n",
        "# Handle missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Convert duration to categorical bins if needed\n",
        "df['recommended_duration'] = df['recommended_duration'].astype('category')\n",
        "\n",
        "# STEP 5: Preprocessing setup\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.drop(['stroke_stage', 'stroke_type',\n",
        "                                                                                  'recommended_doctor', 'medication',\n",
        "                                                                                  'recommended_duration'])\n",
        "numerical_cols = df.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Create column transformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', 'passthrough', numerical_cols),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "    ])\n",
        "\n",
        "# STEP 6: Define outputs\n",
        "output_cols = ['stroke_stage', 'stroke_type', 'recommended_doctor',\n",
        "               'medication', 'recommended_duration']\n",
        "Y = df[output_cols]\n",
        "X = df.drop(columns=output_cols)\n",
        "\n",
        "# STEP 7: Create pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', MultiOutputClassifier(\n",
        "        RandomForestClassifier(n_estimators=200,\n",
        "                              class_weight='balanced',\n",
        "                              random_state=42))\n",
        "    )\n",
        "])\n",
        "\n",
        "# STEP 8: Train model\n",
        "pipeline.fit(X, Y)\n",
        "\n",
        "# STEP 9: Save full pipeline with metadata\n",
        "model_package = {\n",
        "    'model': pipeline,\n",
        "    'input_columns': list(X.columns),\n",
        "    'output_columns': output_cols,\n",
        "    'categorical_cols': list(categorical_cols),\n",
        "    'numerical_cols': list(numerical_cols),\n",
        "    'category_mappings': {\n",
        "        col: dict(enumerate(df[col].astype('category').cat.categories))\n",
        "        for col in output_cols\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('stroke_recommendation_package.pkl', 'wb') as f:\n",
        "    pickle.dump(model_package, f)\n",
        "\n",
        "print(\"✅ Full model package saved as 'stroke_recommendation_package.pkl'\")\n",
        "print(\"Package contains:\")\n",
        "print(\"- Trained pipeline\")\n",
        "print(\"- Input/Output column names\")\n",
        "print(\"- Category mappings for decoding predictions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a-uCfm6-4TM",
        "outputId": "4227b20f-cf89-4e19-ec30-bd316782cdec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Full model package saved as 'stroke_recommendation_package.pkl'\n",
            "Package contains:\n",
            "- Trained pipeline\n",
            "- Input/Output column names\n",
            "- Category mappings for decoding predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download CNN model\n",
        "files.download('/content/drive/MyDrive/Recommendations /stroke_recommendation_package.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ly58WGhb--t0",
        "outputId": "84ecbc97-5021-4e8c-a222-ffa84186acb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e832b743-cf58-4685-a6a1-5c44d91b54c6\", \"stroke_recommendation_package.pkl\", 21669470)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CpCtfHgFY1H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZAurixrWY1At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CexkNGAXY00h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "\n",
        "# 1️⃣ **Load the Dataset**\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Recommendations /Final stroke recommendations .csv\")\n",
        "\n",
        "# 2️⃣ **Define Input (X) & Output (Y) Columns**\n",
        "input_columns = ['age', 'gender', 'hypertension', 'heart_disease', 'ever_married',\n",
        "                 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
        "                 'smoking_status', 'trauma', 'medication_use', 'symptoms_duration']\n",
        "output_columns = ['stroke_type', 'stroke_stage', 'medication', 'recommended_duration', 'recommended_doctor']\n",
        "\n",
        "X = df[input_columns]\n",
        "Y = df[output_columns]\n",
        "\n",
        "# 3️⃣ **Identify Categorical & Numerical Columns**\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# 4️⃣ **Create a Preprocessing Pipeline**\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
        "    ('scaler', StandardScaler(), numerical_cols)\n",
        "])\n",
        "\n",
        "# 5️⃣ **Train the MultiOutput RandomForestClassifier**\n",
        "model = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\")))\n",
        "])\n",
        "\n",
        "# Split the data for training & testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# 6️⃣ **Save the Model**\n",
        "category_mappings = {\n",
        "    col: {i: cat for i, cat in enumerate(df[col].astype('category').cat.categories)}\n",
        "    for col in output_columns\n",
        "}\n",
        "\n",
        "model_package = {\n",
        "    'model': model,\n",
        "    'input_columns': input_columns,\n",
        "    'output_columns': output_columns,\n",
        "    'categorical_cols': categorical_cols,\n",
        "    'numerical_cols': numerical_cols,\n",
        "    'category_mappings': category_mappings\n",
        "}\n",
        "\n",
        "joblib.dump(model_package, \"final_stroke_recommendation_package.pkl\")\n",
        "print(\"✅ Model training complete! Saved as 'Final stroke_recommendation_package.pkl'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs9mS-i3Bzih",
        "outputId": "8069abf3-21d3-4141-ac4b-0dc1f88ed496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model training complete! Saved as 'Final stroke_recommendation_package.pkl'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download CNN model\n",
        "files.download('/content/drive/MyDrive/Recommendations /final_stroke_recommendation_package.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "u9e6SUVKZczp",
        "outputId": "76e6c5b3-84d3-4f93-991e-5d28da831f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1425dc15-565c-439d-a7cf-5f84c197b4bc\", \"final_stroke_recommendation_package.pkl\", 9580408)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "RECOMMENDATION_MODEL_PATH = \"/content/drive/MyDrive/Recommendations /final_stroke_recommendation_package.pkl\"\n",
        "\n",
        "try:\n",
        "    with open(RECOMMENDATION_MODEL_PATH, \"rb\") as f:\n",
        "        model_package = joblib.load(f)  # Load file\n",
        "    print(model_package.keys())  # Show available keys\n",
        "except Exception as e:\n",
        "    print(f\"Error loading file: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHWumuWKafDW",
        "outputId": "1ee4b928-774f-4e31-c868-ff1b00eb8559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['model', 'input_columns', 'output_columns', 'categorical_cols', 'numerical_cols', 'category_mappings'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qZEF9jyFh0fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vuhT163R5EuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4qE8ZJ0o5Erg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EmHBmojf5Ene"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "\n",
        "# 1️⃣ **Load the Dataset**\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Recommendations /Final stroke recommendations .csv\")\n",
        "\n",
        "# 2️⃣ **Define Input (X) & Output (Y) Columns**\n",
        "input_columns = ['age', 'gender', 'hypertension', 'heart_disease', 'ever_married',\n",
        "                 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
        "                 'smoking_status', 'trauma', 'medication_use', 'symptoms_duration']\n",
        "output_columns = ['stroke_type', 'stroke_stage', 'medication', 'recommended_duration', 'recommended_doctor']\n",
        "\n",
        "X = df[input_columns]\n",
        "Y = df[output_columns]\n",
        "\n",
        "# 3️⃣ **Identify Categorical & Numerical Columns**\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# ✅ Ensure categorical outputs are converted to numerical encoding\n",
        "def encode_categorical_outputs(Y_df):\n",
        "    mappings = {}\n",
        "    for col in Y_df.columns:\n",
        "        Y_df[col] = Y_df[col].astype('category')\n",
        "        mappings[col] = {category: i for i, category in enumerate(Y_df[col].cat.categories)}\n",
        "        Y_df[col] = Y_df[col].map(mappings[col])\n",
        "    return Y_df, mappings\n",
        "\n",
        "Y, category_mappings = encode_categorical_outputs(Y)\n",
        "\n",
        "# 4️⃣ **Create a Preprocessing Pipeline**\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
        "    ('scaler', StandardScaler(), numerical_cols)\n",
        "])\n",
        "\n",
        "# 5️⃣ **Train the MultiOutput RandomForestClassifier**\n",
        "model = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\")))\n",
        "])\n",
        "\n",
        "# Split the data for training & testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# 6️⃣ **Save the Model**\n",
        "model_package = {\n",
        "    'model': model,\n",
        "    'input_columns': input_columns,\n",
        "    'output_columns': output_columns,\n",
        "    'categorical_cols': categorical_cols,\n",
        "    'numerical_cols': numerical_cols,\n",
        "    'category_mappings': category_mappings\n",
        "}\n",
        "\n",
        "joblib.dump(model_package, \"updated_final_stroke_recommendation_package.pkl\")\n",
        "print(\"✅ Model training complete! Saved as 'updated_final_stroke_recommendation_package.pkl'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5hcORGdr5Eev",
        "outputId": "52f5a601-f7e4-4ca6-997f-7d5b0407f7cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-bb05ab32a4b1>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Y_df[col] = Y_df[col].astype('category')\n",
            "<ipython-input-2-bb05ab32a4b1>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Y_df[col] = Y_df[col].map(mappings[col])\n",
            "<ipython-input-2-bb05ab32a4b1>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Y_df[col] = Y_df[col].astype('category')\n",
            "<ipython-input-2-bb05ab32a4b1>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Y_df[col] = Y_df[col].map(mappings[col])\n",
            "<ipython-input-2-bb05ab32a4b1>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Y_df[col] = Y_df[col].astype('category')\n",
            "<ipython-input-2-bb05ab32a4b1>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Y_df[col] = Y_df[col].map(mappings[col])\n",
            "<ipython-input-2-bb05ab32a4b1>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Y_df[col] = Y_df[col].astype('category')\n",
            "<ipython-input-2-bb05ab32a4b1>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Y_df[col] = Y_df[col].map(mappings[col])\n",
            "<ipython-input-2-bb05ab32a4b1>:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Y_df[col] = Y_df[col].astype('category')\n",
            "<ipython-input-2-bb05ab32a4b1>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Y_df[col] = Y_df[col].map(mappings[col])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bb05ab32a4b1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# 6️⃣ **Save the Model**\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    660\u001b[0m                     \u001b[0mall_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m                 )\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlast_step_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \"\"\"\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;34m\"multilabel-sequences\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     ]:\n\u001b[0;32m--> 222\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;34mf\"Unknown label type: {y_type}. Maybe you are trying to fit a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"classifier, which expects discrete classes on a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: unknown. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cuhvFy3r5JMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4vk9_Dbh50YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZAnjJGu50PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "\n",
        "# ✅ Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Recommendations /Final stroke recommendations .csv\")\n",
        "\n",
        "# ✅ Define input (X) & output (Y) columns\n",
        "input_columns = ['age', 'gender', 'hypertension', 'heart_disease', 'ever_married',\n",
        "                 'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
        "                 'smoking_status', 'trauma', 'medication_use', 'symptoms_duration']\n",
        "\n",
        "output_columns = ['stroke_type', 'stroke_stage', 'medication', 'recommended_duration', 'recommended_doctor']\n",
        "\n",
        "X = df[input_columns]\n",
        "Y = df[output_columns]\n",
        "\n",
        "# ✅ Handle missing values\n",
        "X.fillna(\"Unknown\", inplace=True)  # Fill missing categorical values\n",
        "Y.dropna(inplace=True)  # Drop rows with missing output values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siheNgCp51Hf",
        "outputId": "8a87c5fe-e1ec-4739-ae4a-276a245b671b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-efd8975a7f47>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X.fillna(\"Unknown\", inplace=True)  # Fill missing categorical values\n",
            "<ipython-input-4-efd8975a7f47>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Y.dropna(inplace=True)  # Drop rows with missing output values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# ✅ Encode output variables (Y) properly\n",
        "category_mappings = {}\n",
        "Y_encoded = Y.copy()\n",
        "\n",
        "for col in output_columns:\n",
        "    Y_encoded[col] = Y_encoded[col].astype(\"category\")  # Ensure categorical type\n",
        "    Y_encoded[col] = Y_encoded[col].cat.codes  # Convert to integer category codes\n",
        "    category_mappings[col] = {cat: i for i, cat in enumerate(Y[col].astype(\"category\").cat.categories)}\n",
        "\n",
        "# ✅ Check if encoding worked correctly\n",
        "print(Y_encoded.dtypes)  # Should show \"int\" types for all target columns\n",
        "\n",
        "# ✅ Split the data for training & testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Train the model\n",
        "model.fit(X_train, Y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "RYmvpBZo53Cx",
        "outputId": "3ebc02e7-b120-4c9d-f492-f21cf24c6533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "stroke_type             int8\n",
            "stroke_stage            int8\n",
            "medication              int8\n",
            "recommended_duration    int8\n",
            "recommended_doctor      int8\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('onehot',\n",
              "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
              "                                                  ['gender', 'ever_married',\n",
              "                                                   'work_type',\n",
              "                                                   'Residence_type',\n",
              "                                                   'smoking_status', 'trauma',\n",
              "                                                   'medication_use',\n",
              "                                                   'symptoms_duration']),\n",
              "                                                 ('scaler', StandardScaler(),\n",
              "                                                  ['age', 'hypertension',\n",
              "                                                   'heart_disease',\n",
              "                                                   'avg_glucose_level',\n",
              "                                                   'bmi'])])),\n",
              "                ('classifier',\n",
              "                 MultiOutputClassifier(estimator=RandomForestClassifier(class_weight='balanced',\n",
              "                                                                        random_state=42)))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;gender&#x27;, &#x27;ever_married&#x27;,\n",
              "                                                   &#x27;work_type&#x27;,\n",
              "                                                   &#x27;Residence_type&#x27;,\n",
              "                                                   &#x27;smoking_status&#x27;, &#x27;trauma&#x27;,\n",
              "                                                   &#x27;medication_use&#x27;,\n",
              "                                                   &#x27;symptoms_duration&#x27;]),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler(),\n",
              "                                                  [&#x27;age&#x27;, &#x27;hypertension&#x27;,\n",
              "                                                   &#x27;heart_disease&#x27;,\n",
              "                                                   &#x27;avg_glucose_level&#x27;,\n",
              "                                                   &#x27;bmi&#x27;])])),\n",
              "                (&#x27;classifier&#x27;,\n",
              "                 MultiOutputClassifier(estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                                                        random_state=42)))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;gender&#x27;, &#x27;ever_married&#x27;,\n",
              "                                                   &#x27;work_type&#x27;,\n",
              "                                                   &#x27;Residence_type&#x27;,\n",
              "                                                   &#x27;smoking_status&#x27;, &#x27;trauma&#x27;,\n",
              "                                                   &#x27;medication_use&#x27;,\n",
              "                                                   &#x27;symptoms_duration&#x27;]),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler(),\n",
              "                                                  [&#x27;age&#x27;, &#x27;hypertension&#x27;,\n",
              "                                                   &#x27;heart_disease&#x27;,\n",
              "                                                   &#x27;avg_glucose_level&#x27;,\n",
              "                                                   &#x27;bmi&#x27;])])),\n",
              "                (&#x27;classifier&#x27;,\n",
              "                 MultiOutputClassifier(estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                                                        random_state=42)))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessor: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
              "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;gender&#x27;, &#x27;ever_married&#x27;, &#x27;work_type&#x27;,\n",
              "                                  &#x27;Residence_type&#x27;, &#x27;smoking_status&#x27;, &#x27;trauma&#x27;,\n",
              "                                  &#x27;medication_use&#x27;, &#x27;symptoms_duration&#x27;]),\n",
              "                                (&#x27;scaler&#x27;, StandardScaler(),\n",
              "                                 [&#x27;age&#x27;, &#x27;hypertension&#x27;, &#x27;heart_disease&#x27;,\n",
              "                                  &#x27;avg_glucose_level&#x27;, &#x27;bmi&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>onehot</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;gender&#x27;, &#x27;ever_married&#x27;, &#x27;work_type&#x27;, &#x27;Residence_type&#x27;, &#x27;smoking_status&#x27;, &#x27;trauma&#x27;, &#x27;medication_use&#x27;, &#x27;symptoms_duration&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>scaler</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;age&#x27;, &#x27;hypertension&#x27;, &#x27;heart_disease&#x27;, &#x27;avg_glucose_level&#x27;, &#x27;bmi&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>classifier: MultiOutputClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.multioutput.MultiOutputClassifier.html\">?<span>Documentation for classifier: MultiOutputClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                                       random_state=42))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Create a preprocessing pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
        "    ('scaler', StandardScaler(), numerical_cols)\n",
        "])\n",
        "\n",
        "# ✅ Train MultiOutput RandomForestClassifier\n",
        "model = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', MultiOutputClassifier(RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\")))\n",
        "])\n",
        "\n",
        "# ✅ Split the data for training & testing\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Train the model\n",
        "model.fit(X_train, Y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "RFLS3P846L_-",
        "outputId": "91f8a0ec-ff59-4770-9338-85a94ec46fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('onehot',\n",
              "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
              "                                                  ['gender', 'ever_married',\n",
              "                                                   'work_type',\n",
              "                                                   'Residence_type',\n",
              "                                                   'smoking_status', 'trauma',\n",
              "                                                   'medication_use',\n",
              "                                                   'symptoms_duration']),\n",
              "                                                 ('scaler', StandardScaler(),\n",
              "                                                  ['age', 'hypertension',\n",
              "                                                   'heart_disease',\n",
              "                                                   'avg_glucose_level',\n",
              "                                                   'bmi'])])),\n",
              "                ('classifier',\n",
              "                 MultiOutputClassifier(estimator=RandomForestClassifier(class_weight='balanced',\n",
              "                                                                        random_state=42)))])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;gender&#x27;, &#x27;ever_married&#x27;,\n",
              "                                                   &#x27;work_type&#x27;,\n",
              "                                                   &#x27;Residence_type&#x27;,\n",
              "                                                   &#x27;smoking_status&#x27;, &#x27;trauma&#x27;,\n",
              "                                                   &#x27;medication_use&#x27;,\n",
              "                                                   &#x27;symptoms_duration&#x27;]),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler(),\n",
              "                                                  [&#x27;age&#x27;, &#x27;hypertension&#x27;,\n",
              "                                                   &#x27;heart_disease&#x27;,\n",
              "                                                   &#x27;avg_glucose_level&#x27;,\n",
              "                                                   &#x27;bmi&#x27;])])),\n",
              "                (&#x27;classifier&#x27;,\n",
              "                 MultiOutputClassifier(estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                                                        random_state=42)))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
              "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                                  [&#x27;gender&#x27;, &#x27;ever_married&#x27;,\n",
              "                                                   &#x27;work_type&#x27;,\n",
              "                                                   &#x27;Residence_type&#x27;,\n",
              "                                                   &#x27;smoking_status&#x27;, &#x27;trauma&#x27;,\n",
              "                                                   &#x27;medication_use&#x27;,\n",
              "                                                   &#x27;symptoms_duration&#x27;]),\n",
              "                                                 (&#x27;scaler&#x27;, StandardScaler(),\n",
              "                                                  [&#x27;age&#x27;, &#x27;hypertension&#x27;,\n",
              "                                                   &#x27;heart_disease&#x27;,\n",
              "                                                   &#x27;avg_glucose_level&#x27;,\n",
              "                                                   &#x27;bmi&#x27;])])),\n",
              "                (&#x27;classifier&#x27;,\n",
              "                 MultiOutputClassifier(estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                                                        random_state=42)))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessor: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
              "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
              "                                 [&#x27;gender&#x27;, &#x27;ever_married&#x27;, &#x27;work_type&#x27;,\n",
              "                                  &#x27;Residence_type&#x27;, &#x27;smoking_status&#x27;, &#x27;trauma&#x27;,\n",
              "                                  &#x27;medication_use&#x27;, &#x27;symptoms_duration&#x27;]),\n",
              "                                (&#x27;scaler&#x27;, StandardScaler(),\n",
              "                                 [&#x27;age&#x27;, &#x27;hypertension&#x27;, &#x27;heart_disease&#x27;,\n",
              "                                  &#x27;avg_glucose_level&#x27;, &#x27;bmi&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>onehot</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;gender&#x27;, &#x27;ever_married&#x27;, &#x27;work_type&#x27;, &#x27;Residence_type&#x27;, &#x27;smoking_status&#x27;, &#x27;trauma&#x27;, &#x27;medication_use&#x27;, &#x27;symptoms_duration&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>scaler</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;age&#x27;, &#x27;hypertension&#x27;, &#x27;heart_disease&#x27;, &#x27;avg_glucose_level&#x27;, &#x27;bmi&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>classifier: MultiOutputClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.multioutput.MultiOutputClassifier.html\">?<span>Documentation for classifier: MultiOutputClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultiOutputClassifier(estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
              "                                                       random_state=42))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Save model & mappings\n",
        "model_package = {\n",
        "    'model': model,\n",
        "    'input_columns': input_columns,\n",
        "    'output_columns': output_columns,\n",
        "    'categorical_cols': categorical_cols,\n",
        "    'numerical_cols': numerical_cols,\n",
        "    'category_mappings': category_mappings  # Save category mappings\n",
        "}\n",
        "\n",
        "joblib.dump(model_package, \"updated_final_stroke_recommendation_package.pkl\")\n",
        "print(\"✅ Model training complete! Saved as 'final_stroke_recommendation_package.pkl'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQeL2JFz6mwo",
        "outputId": "adae48f2-7a3e-4d55-deec-9741790a8e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model training complete! Saved as 'final_stroke_recommendation_package.pkl'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# ✅ Ensure Y_test is converted to string categories\n",
        "Y_test_decoded = pd.DataFrame(Y_test.copy())  # Create a copy to avoid modifying the original data\n",
        "\n",
        "for col in Y_test_decoded.columns:\n",
        "    if col in category_mappings:\n",
        "        Y_test_decoded[col] = Y_test_decoded[col].map({v: k for k, v in category_mappings[col].items()})  # Reverse mapping\n",
        "\n",
        "# ✅ Ensure Y_pred is fully decoded into categories\n",
        "Y_pred_decoded = pd.DataFrame(Y_pred, columns=Y_test.columns)\n",
        "\n",
        "for col in Y_pred_decoded.columns:\n",
        "    if col in category_mappings:\n",
        "        Y_pred_decoded[col] = Y_pred_decoded[col].round().astype(int)  # Convert float predictions to int\n",
        "        Y_pred_decoded[col] = Y_pred_decoded[col].map({v: k for k, v in category_mappings[col].items()})  # Reverse mapping\n",
        "\n",
        "# ✅ Check Model Performance\n",
        "print(\"🔹 Model Performance:\")\n",
        "for col in Y_test.columns:\n",
        "    print(f\"\\n🎯 {col}:\")\n",
        "    print(classification_report(Y_test_decoded[col], Y_pred_decoded[col]))\n",
        "\n",
        "# ✅ Overall Accuracy\n",
        "overall_accuracy = accuracy_score(Y_test_decoded.values.flatten(), Y_pred_decoded.values.flatten())\n",
        "print(f\"\\n✅ Overall Accuracy: {overall_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiRa2oEL62KQ",
        "outputId": "35586eda-00a4-4f03-c570-4eb76bfc915c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Model Performance:\n",
            "\n",
            "🎯 stroke_type:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " Hemorrhagic       1.00      1.00      1.00        40\n",
            "    Ischemic       1.00      1.00      1.00       200\n",
            "         TIA       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00       245\n",
            "   macro avg       1.00      1.00      1.00       245\n",
            "weighted avg       1.00      1.00      1.00       245\n",
            "\n",
            "\n",
            "🎯 stroke_stage:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Critical       1.00      0.94      0.97        36\n",
            "       Early       0.99      1.00      0.99        76\n",
            "    Moderate       0.99      0.99      0.99       133\n",
            "\n",
            "    accuracy                           0.99       245\n",
            "   macro avg       0.99      0.98      0.98       245\n",
            "weighted avg       0.99      0.99      0.99       245\n",
            "\n",
            "\n",
            "🎯 medication:\n",
            "                                 precision    recall  f1-score   support\n",
            "\n",
            "Alteplase + Intensive Care Meds       1.00      0.94      0.97        36\n",
            "                        Aspirin       0.99      1.00      0.99        76\n",
            "   Clopidogrel + Blood Thinners       0.99      0.99      0.99       133\n",
            "\n",
            "                       accuracy                           0.99       245\n",
            "                      macro avg       0.99      0.98      0.98       245\n",
            "                   weighted avg       0.99      0.99      0.99       245\n",
            "\n",
            "\n",
            "🎯 recommended_duration:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     14 days       0.99      0.99      0.99       133\n",
            "    21+ days       1.00      0.94      0.97        36\n",
            "      7 days       0.99      1.00      0.99        76\n",
            "\n",
            "    accuracy                           0.99       245\n",
            "   macro avg       0.99      0.98      0.98       245\n",
            "weighted avg       0.99      0.99      0.99       245\n",
            "\n",
            "\n",
            "🎯 recommended_doctor:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "General Physician       0.99      1.00      0.99        76\n",
            "      Neurologist       0.99      0.99      0.99       133\n",
            "Stroke Specialist       1.00      0.94      0.97        36\n",
            "\n",
            "         accuracy                           0.99       245\n",
            "        macro avg       0.99      0.98      0.98       245\n",
            "     weighted avg       0.99      0.99      0.99       245\n",
            "\n",
            "\n",
            "✅ Overall Accuracy: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download CNN model\n",
        "files.download('/content/updated_final_stroke_recommendation_package.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_wJkv-Ql7uIX",
        "outputId": "3effbcf6-d25e-473a-ccc6-ebaf22a3fcd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dd7f45ab-c62e-499c-937d-63c4c7398c1e\", \"updated_final_stroke_recommendation_package.pkl\", 9586071)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CeaKI4IQGpDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cmsn48TCGpBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# ✅ Load dataset\n",
        "file_path = \"/content/drive/MyDrive/Recommendations /Final stroke recommendations .csv\"  # Update path if needed\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# ✅ Define input and output labels\n",
        "output_labels = [\"stroke_stage\", \"stroke_type\", \"recommended_doctor\", \"medication\", \"recommended_duration\"]\n",
        "input_labels = [col for col in df.columns if col not in output_labels]\n",
        "\n",
        "# ✅ Separate inputs and outputs\n",
        "X = df[input_labels].copy()\n",
        "Y = df[output_labels].copy()\n",
        "\n",
        "# ✅ Identify categorical and numerical features\n",
        "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "numerical_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "\n",
        "# ✅ Encode categorical inputs\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "X_categorical = encoder.fit_transform(X[categorical_features])\n",
        "\n",
        "# ✅ Scale numerical inputs\n",
        "scaler = MinMaxScaler()\n",
        "X_numerical = scaler.fit_transform(X[numerical_features])\n",
        "\n",
        "# ✅ Ensure correct dimensions for stacking\n",
        "X_numerical = X_numerical.reshape(-1, 1) if X_numerical.ndim == 1 else X_numerical\n",
        "X = np.hstack([X_categorical, X_numerical])\n",
        "\n",
        "# ✅ Encode output labels\n",
        "label_encoders = {}\n",
        "Y_encoded = {}\n",
        "\n",
        "for col in output_labels:\n",
        "    le = LabelEncoder()\n",
        "    Y_encoded[col] = le.fit_transform(Y[col])\n",
        "    label_encoders[col] = le  # Store for decoding later\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "Y_encoded = [np.array(Y_encoded[col]) for col in output_labels]\n",
        "\n",
        "# ✅ Split dataset\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Define Multi-Task MLP Model\n",
        "input_layer = Input(shape=(X.shape[1],))\n",
        "\n",
        "# Shared hidden layers\n",
        "hidden1 = Dense(64, activation=\"relu\")(input_layer)\n",
        "hidden2 = Dense(32, activation=\"relu\")(hidden1)\n",
        "\n",
        "# Separate output layers\n",
        "outputs = []\n",
        "for col in output_labels:\n",
        "    outputs.append(Dense(len(label_encoders[col].classes_), activation=\"softmax\", name=col)(hidden2))\n",
        "\n",
        "# Compile model\n",
        "model = Model(inputs=input_layer, outputs=outputs)\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=[\"sparse_categorical_crossentropy\"] * len(output_labels),\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# ✅ Train Model\n",
        "history = model.fit(\n",
        "    X_train, Y_train,\n",
        "    validation_data=(X_test, Y_test),\n",
        "    epochs=50, batch_size=16\n",
        ")\n",
        "\n",
        "# ✅ Save Model & Encoders\n",
        "model.save(\"/mnt/data/stroke_recommendation_model.h5\")\n",
        "joblib.dump(encoder, \"/mnt/data/input_encoder.pkl\")\n",
        "joblib.dump(scaler, \"/mnt/data/input_scaler.pkl\")\n",
        "joblib.dump(label_encoders, \"/mnt/data/output_label_encoders.pkl\")\n",
        "\n",
        "print(\"✅ Model & encoders saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VPwxsm0qGo-j",
        "outputId": "54978758-5e38-4885-e97d-b037d3b26be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [1222, 5]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-541f6e334fb3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# ✅ Split dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# ✅ Define Multi-Task MLP Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2846\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2848\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1222, 5]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qj7JXgAoK8gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6KCJmFVK8jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwNMV44dK8n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# ✅ Load dataset\n",
        "file_path = \"/content/drive/MyDrive/Recommendations /Final stroke recommendations .csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# ✅ Identify time-related columns (without affecting other fields)\n",
        "time_units = [\"day\", \"hour\", \"h\", \"hrs\"]\n",
        "\n",
        "def contains_time_units(value):\n",
        "    return isinstance(value, str) and any(unit in value.lower() for unit in time_units)\n",
        "\n",
        "columns_with_time = [col for col in df.columns if df[col].astype(str).apply(contains_time_units).any()]\n",
        "\n",
        "# ✅ Extract only numbers from time-related fields (Keep other fields unchanged)\n",
        "def extract_number(value):\n",
        "    if isinstance(value, str):\n",
        "        match = re.search(r'\\d+', value)  # Extract numeric part\n",
        "        return int(match.group()) if match else np.nan\n",
        "    return value  # Keep non-string values unchanged\n",
        "\n",
        "for col in columns_with_time:\n",
        "    df[col] = df[col].apply(extract_number)\n",
        "\n",
        "# ✅ Fill missing values **only for time-related fields**\n",
        "for col in columns_with_time:\n",
        "    if df[col].isnull().sum() > 0:\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "# ✅ Save cleaned dataset **without removing stroke type, doctor, or medication**\n",
        "cleaned_path = \"/content/drive/MyDrive/Recommendations /final_cleaned_stroke_data.csv\"\n",
        "df.to_csv(cleaned_path, index=False)\n",
        "print(f\"✅ Cleaned dataset saved at: {cleaned_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSUggehpJC2I",
        "outputId": "fcd72551-4597-4ee2-d209-2d02d48e0d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cleaned dataset saved at: /content/drive/MyDrive/Recommendations /final_cleaned_stroke_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DjMS1CHG1pvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9sMdNp8_wh2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "claude"
      ],
      "metadata": {
        "id": "jmlvrQYGwhnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "class StrokeRecommendationModel:\n",
        "    def __init__(self, input_columns, output_columns):\n",
        "        \"\"\"\n",
        "        Initialize Stroke Recommendation Model\n",
        "\n",
        "        Args:\n",
        "            input_columns (list): Input feature columns\n",
        "            output_columns (list): Target prediction columns\n",
        "        \"\"\"\n",
        "        self.input_columns = input_columns\n",
        "        self.output_columns = output_columns\n",
        "\n",
        "        # Initialize label encoders for output columns\n",
        "        self.label_encoders = {col: LabelEncoder() for col in output_columns}\n",
        "\n",
        "        # Model and preprocessing components\n",
        "        self.model = None\n",
        "        self.preprocessor = None\n",
        "\n",
        "        # Mapping dictionaries\n",
        "        self.input_mappings = {}\n",
        "        self.output_mappings = {}\n",
        "\n",
        "    def preprocess_data(self, X, Y):\n",
        "        \"\"\"\n",
        "        Preprocess input and output data\n",
        "\n",
        "        Args:\n",
        "            X (pd.DataFrame): Input features\n",
        "            Y (pd.DataFrame): Target variables\n",
        "\n",
        "        Returns:\n",
        "            tuple: Processed X and Y\n",
        "        \"\"\"\n",
        "        # Handle missing values\n",
        "        X_processed = X.copy()\n",
        "        Y_processed = Y.copy()\n",
        "\n",
        "        X_processed.fillna('Unknown', inplace=True)\n",
        "        Y_processed.dropna(inplace=True)\n",
        "\n",
        "        # Separate categorical and numerical columns\n",
        "        self.categorical_cols = X_processed.select_dtypes(include=['object']).columns.tolist()\n",
        "        self.numerical_cols = X_processed.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "        # Encode output columns\n",
        "        Y_encoded = Y_processed.copy()\n",
        "        for col in self.output_columns:\n",
        "            # Fit label encoder and transform\n",
        "            Y_encoded[col] = self.label_encoders[col].fit_transform(Y_processed[col])\n",
        "\n",
        "            # Store mappings for reverse lookup\n",
        "            self.output_mappings[col] = {\n",
        "                idx: label for idx, label in enumerate(self.label_encoders[col].classes_)\n",
        "            }\n",
        "\n",
        "        return X_processed, Y_encoded\n",
        "\n",
        "    def create_preprocessing_pipeline(self):\n",
        "        \"\"\"\n",
        "        Create preprocessing pipeline for features\n",
        "\n",
        "        Returns:\n",
        "            ColumnTransformer: Preprocessor for features\n",
        "        \"\"\"\n",
        "        self.preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', StandardScaler(), self.numerical_cols),\n",
        "                ('cat', OneHotEncoder(handle_unknown='ignore'), self.categorical_cols)\n",
        "            ])\n",
        "\n",
        "        return self.preprocessor\n",
        "\n",
        "    def create_model_pipeline(self):\n",
        "        \"\"\"\n",
        "        Create machine learning pipeline\n",
        "\n",
        "        Returns:\n",
        "            Pipeline: Complete model pipeline\n",
        "        \"\"\"\n",
        "        self.model = Pipeline([\n",
        "            ('preprocessor', self.create_preprocessing_pipeline()),\n",
        "            ('classifier', MultiOutputClassifier(\n",
        "                RandomForestClassifier(\n",
        "                    n_estimators=100,\n",
        "                    random_state=42,\n",
        "                    class_weight='balanced'\n",
        "                )\n",
        "            ))\n",
        "        ])\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def train(self, X, Y, test_size=0.2, random_state=42):\n",
        "        \"\"\"\n",
        "        Train the model\n",
        "\n",
        "        Args:\n",
        "            X (pd.DataFrame): Input features\n",
        "            Y (pd.DataFrame): Target variables\n",
        "            test_size (float): Proportion of test data\n",
        "            random_state (int): Random seed for reproducibility\n",
        "        \"\"\"\n",
        "        # Preprocess data\n",
        "        X_processed, Y_processed = self.preprocess_data(X, Y)\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "            X_processed, Y_processed,\n",
        "            test_size=test_size,\n",
        "            random_state=random_state\n",
        "        )\n",
        "\n",
        "        # Create and train model\n",
        "        self.create_model_pipeline()\n",
        "        self.model.fit(X_train, Y_train)\n",
        "\n",
        "        # Evaluate model\n",
        "        Y_pred = self.model.predict(X_test)\n",
        "\n",
        "        # Print classification report for each output column\n",
        "        for i, col in enumerate(self.output_columns):\n",
        "            print(f\"\\nClassification Report for {col}:\")\n",
        "            print(classification_report(\n",
        "                Y_test.iloc[:, i],\n",
        "                Y_pred[:, i]\n",
        "            ))\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Make predictions\n",
        "\n",
        "        Args:\n",
        "            X (pd.DataFrame): Input features\n",
        "\n",
        "        Returns:\n",
        "            list: Decoded predictions\n",
        "        \"\"\"\n",
        "        # Ensure input matches training columns\n",
        "        X_processed = X.reindex(columns=self.input_columns, fill_value='Unknown')\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = self.model.predict(X_processed)\n",
        "\n",
        "        # Decode predictions\n",
        "        decoded_predictions = {}\n",
        "        for i, col in enumerate(self.output_columns):\n",
        "            decoded_predictions[col] = self.output_mappings[col].get(\n",
        "                predictions[0][i],\n",
        "                f\"Unknown_{col}_Category\"\n",
        "            )\n",
        "\n",
        "        return decoded_predictions\n",
        "\n",
        "    def save_model(self, filename='claude_stroke_recommendation_model.pkl'):\n",
        "        \"\"\"\n",
        "        Save trained model and associated metadata\n",
        "\n",
        "        Args:\n",
        "            filename (str): Path to save model\n",
        "        \"\"\"\n",
        "        model_package = {\n",
        "            'model': self.model,\n",
        "            'input_columns': self.input_columns,\n",
        "            'output_columns': self.output_columns,\n",
        "            'categorical_cols': self.categorical_cols,\n",
        "            'numerical_cols': self.numerical_cols,\n",
        "            'output_mappings': self.output_mappings,\n",
        "            'label_encoders': self.label_encoders\n",
        "        }\n",
        "\n",
        "        joblib.dump(model_package, filename)\n",
        "        print(f\"✅ Model saved successfully to {filename}\")\n",
        "\n",
        "    def load_model(self, filename='claude_stroke_recommendation_model.pkl'):\n",
        "        \"\"\"\n",
        "        Load saved model\n",
        "\n",
        "        Args:\n",
        "            filename (str): Path to load model from\n",
        "\n",
        "        Returns:\n",
        "            dict: Loaded model package\n",
        "        \"\"\"\n",
        "        return joblib.load(filename)\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/Recommendations /final modified recommendations file.csv\")\n",
        "\n",
        "    # Define input and output columns\n",
        "    input_columns = [\n",
        "        'age', 'gender', 'hypertension', 'heart_disease', 'ever_married',\n",
        "        'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
        "        'smoking_status', 'trauma', 'medication_use', 'symptoms_duration'\n",
        "    ]\n",
        "\n",
        "    output_columns = [\n",
        "        'stroke_type', 'stroke_stage', 'medication',\n",
        "        'recommended_duration', 'recommended_doctor'\n",
        "    ]\n",
        "\n",
        "    # Initialize model\n",
        "    model = StrokeRecommendationModel(input_columns, output_columns)\n",
        "\n",
        "    # Select input and output data\n",
        "    X = df[input_columns]\n",
        "    Y = df[output_columns]\n",
        "\n",
        "    # Train model\n",
        "    model.train(X, Y)\n",
        "\n",
        "    # Save model\n",
        "    model.save_model()\n",
        "\n",
        "    # Example prediction\n",
        "    sample_input = X.iloc[[0]]  # Take first row as example\n",
        "    predictions = model.predict(sample_input)\n",
        "    print(\"Sample Predictions:\", predictions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lCSGEFZwhJ2",
        "outputId": "5842d791-7024-499f-f267-980f573b012f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report for stroke_type:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        40\n",
            "           1       1.00      1.00      1.00       200\n",
            "           2       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00       245\n",
            "   macro avg       1.00      1.00      1.00       245\n",
            "weighted avg       1.00      1.00      1.00       245\n",
            "\n",
            "\n",
            "Classification Report for stroke_stage:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        36\n",
            "           1       0.99      1.00      0.99        76\n",
            "           2       0.99      0.99      0.99       133\n",
            "\n",
            "    accuracy                           0.99       245\n",
            "   macro avg       0.99      0.99      0.99       245\n",
            "weighted avg       0.99      0.99      0.99       245\n",
            "\n",
            "\n",
            "Classification Report for medication:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        36\n",
            "           1       0.99      1.00      0.99        76\n",
            "           2       0.99      0.99      0.99       133\n",
            "\n",
            "    accuracy                           0.99       245\n",
            "   macro avg       0.99      0.99      0.99       245\n",
            "weighted avg       0.99      0.99      0.99       245\n",
            "\n",
            "\n",
            "Classification Report for recommended_duration:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99        76\n",
            "           1       0.99      0.99      0.99       133\n",
            "           2       1.00      0.94      0.97        36\n",
            "\n",
            "    accuracy                           0.99       245\n",
            "   macro avg       0.99      0.98      0.98       245\n",
            "weighted avg       0.99      0.99      0.99       245\n",
            "\n",
            "\n",
            "Classification Report for recommended_doctor:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99        76\n",
            "           1       0.99      0.99      0.99       133\n",
            "           2       1.00      0.94      0.97        36\n",
            "\n",
            "    accuracy                           0.99       245\n",
            "   macro avg       0.99      0.98      0.98       245\n",
            "weighted avg       0.99      0.99      0.99       245\n",
            "\n",
            "✅ Model saved successfully to claude_stroke_recommendation_model.pkl\n",
            "Sample Predictions: {'stroke_type': 'Ischemic', 'stroke_stage': 'Critical', 'medication': 'Alteplase + Intensive Care Meds', 'recommended_duration': np.int64(21), 'recommended_doctor': 'Stroke Specialist'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f_6YNy-2xB3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation script"
      ],
      "metadata": {
        "id": "jIpj8TXry1VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "class StrokeRecommendationModelValidator:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize model validator\n",
        "        \"\"\"\n",
        "        # Define input and output columns\n",
        "        self.input_columns = [\n",
        "            'age', 'gender', 'hypertension', 'heart_disease', 'ever_married',\n",
        "            'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
        "            'smoking_status', 'trauma', 'medication_use', 'symptoms_duration'\n",
        "        ]\n",
        "\n",
        "        self.output_columns = [\n",
        "            'stroke_type', 'stroke_stage', 'medication',\n",
        "            'recommended_duration', 'recommended_doctor'\n",
        "        ]\n",
        "\n",
        "        # Define column types\n",
        "        self.numerical_cols = [\n",
        "            'age', 'avg_glucose_level', 'bmi', 'symptoms_duration'\n",
        "        ]\n",
        "\n",
        "        self.categorical_cols = [\n",
        "            'gender', 'hypertension', 'heart_disease', 'ever_married',\n",
        "            'work_type', 'Residence_type', 'smoking_status',\n",
        "            'trauma', 'medication_use'\n",
        "        ]\n",
        "\n",
        "        # Initialize label encoders\n",
        "        self.label_encoders = {}\n",
        "\n",
        "    def _create_preprocessor(self):\n",
        "        \"\"\"\n",
        "        Create preprocessing pipeline\n",
        "\n",
        "        Returns:\n",
        "            ColumnTransformer: Preprocessor for features\n",
        "        \"\"\"\n",
        "        return ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', StandardScaler(), self.numerical_cols),\n",
        "                ('cat', OneHotEncoder(handle_unknown='ignore'), self.categorical_cols)\n",
        "            ])\n",
        "\n",
        "    def _encode_targets(self, Y):\n",
        "        \"\"\"\n",
        "        Encode target variables\n",
        "\n",
        "        Args:\n",
        "            Y (pd.DataFrame): Target variables\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Encoded target variables\n",
        "        \"\"\"\n",
        "        # Create a copy of the dataframe\n",
        "        Y_encoded = Y.copy()\n",
        "\n",
        "        # Encode each output column\n",
        "        for col in self.output_columns:\n",
        "            # Check if column needs encoding\n",
        "            if Y[col].dtype == 'object':\n",
        "                # Create label encoder if not exists\n",
        "                if col not in self.label_encoders:\n",
        "                    le = LabelEncoder()\n",
        "                    Y_encoded[col] = le.fit_transform(Y[col])\n",
        "                    self.label_encoders[col] = le\n",
        "                else:\n",
        "                    le = self.label_encoders[col]\n",
        "                    Y_encoded[col] = le.transform(Y[col])\n",
        "\n",
        "        # Convert to numpy array\n",
        "        return Y_encoded[self.output_columns].values\n",
        "\n",
        "    def validate_model(self, X, Y):\n",
        "        \"\"\"\n",
        "        Perform comprehensive model validation\n",
        "\n",
        "        Args:\n",
        "            X (pd.DataFrame): Input features\n",
        "            Y (pd.DataFrame): Target variables\n",
        "        \"\"\"\n",
        "        # Ensure input matches expected columns\n",
        "        X_processed = X.reindex(columns=self.input_columns, fill_value='Unknown')\n",
        "\n",
        "        # Encode target variables\n",
        "        Y_multi = self._encode_targets(Y)\n",
        "\n",
        "        # Create model pipeline\n",
        "        model = Pipeline([\n",
        "            ('preprocessor', self._create_preprocessor()),\n",
        "            ('classifier', RandomForestClassifier(\n",
        "                n_estimators=100,\n",
        "                random_state=42,\n",
        "                class_weight='balanced'\n",
        "            ))\n",
        "        ])\n",
        "\n",
        "        # Use standard KFold\n",
        "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "        # Perform cross-validation for each output column\n",
        "        print(\"\\nCross-Validation Results:\")\n",
        "        for i, col in enumerate(self.output_columns):\n",
        "            print(f\"\\nValidation for {col}:\")\n",
        "\n",
        "            # Perform cross-validation\n",
        "            cv_scores = cross_val_score(\n",
        "                model,\n",
        "                X_processed,\n",
        "                Y_multi[:, i],\n",
        "                cv=kf,\n",
        "                scoring='accuracy'\n",
        "            )\n",
        "\n",
        "            print(f\"Cross-validation scores: {cv_scores}\")\n",
        "            print(f\"Mean CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "    def analyze_feature_importance(self, X, Y):\n",
        "        \"\"\"\n",
        "        Analyze feature importance for each target variable\n",
        "\n",
        "        Args:\n",
        "            X (pd.DataFrame): Input features\n",
        "            Y (pd.DataFrame): Target variables\n",
        "        \"\"\"\n",
        "        # Ensure input matches expected columns\n",
        "        X_processed = X.reindex(columns=self.input_columns, fill_value='Unknown')\n",
        "\n",
        "        # Encode target variables\n",
        "        Y_multi = self._encode_targets(Y)\n",
        "\n",
        "        # Create preprocessor and fit\n",
        "        preprocessor = self._create_preprocessor()\n",
        "        X_transformed = preprocessor.fit_transform(X_processed)\n",
        "\n",
        "        # Prepare feature names\n",
        "        feature_names = (\n",
        "            self.numerical_cols +\n",
        "            list(preprocessor.named_transformers_['cat']\n",
        "                 .get_feature_names_out(self.categorical_cols))\n",
        "        )\n",
        "\n",
        "        # Analyze feature importance for each output column\n",
        "        for i, col in enumerate(self.output_columns):\n",
        "            print(f\"\\nFeature Importance for {col}:\")\n",
        "\n",
        "            # Create and fit model\n",
        "            clf = RandomForestClassifier(\n",
        "                n_estimators=100,\n",
        "                random_state=42,\n",
        "                class_weight='balanced'\n",
        "            )\n",
        "            clf.fit(X_transformed, Y_multi[:, i])\n",
        "\n",
        "            # Get feature importances\n",
        "            importances = clf.feature_importances_\n",
        "\n",
        "            # Create and sort feature importance DataFrame\n",
        "            feature_importance = pd.DataFrame({\n",
        "                'feature': feature_names,\n",
        "                'importance': importances\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            print(feature_importance.head(10))\n",
        "\n",
        "def main():\n",
        "    # Load your dataset\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/Recommendations /final modified recommendations file.csv\")\n",
        "\n",
        "    # Prepare data\n",
        "    X = df[[\n",
        "        'age', 'gender', 'hypertension', 'heart_disease', 'ever_married',\n",
        "        'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
        "        'smoking_status', 'trauma', 'medication_use', 'symptoms_duration'\n",
        "    ]]\n",
        "\n",
        "    Y = df[[\n",
        "        'stroke_type', 'stroke_stage', 'medication',\n",
        "        'recommended_duration', 'recommended_doctor'\n",
        "    ]]\n",
        "\n",
        "    # Initialize model validator\n",
        "    model_validator = StrokeRecommendationModelValidator()\n",
        "\n",
        "    # Validate model\n",
        "    model_validator.validate_model(X, Y)\n",
        "\n",
        "    # Analyze feature importance\n",
        "    model_validator.analyze_feature_importance(X, Y)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Pc9nkmRy1MG",
        "outputId": "259379df-fc02-44cb-8ac3-8ba70e88985f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cross-Validation Results:\n",
            "\n",
            "Validation for stroke_type:\n",
            "Cross-validation scores: [1.         0.99591837 1.         1.         1.        ]\n",
            "Mean CV Score: 0.9992 (+/- 0.0033)\n",
            "\n",
            "Validation for stroke_stage:\n",
            "Cross-validation scores: [0.99591837 1.         0.99180328 0.99180328 0.9795082 ]\n",
            "Mean CV Score: 0.9918 (+/- 0.0137)\n",
            "\n",
            "Validation for medication:\n",
            "Cross-validation scores: [0.99591837 1.         0.99180328 0.99180328 0.9795082 ]\n",
            "Mean CV Score: 0.9918 (+/- 0.0137)\n",
            "\n",
            "Validation for recommended_duration:\n",
            "Cross-validation scores: [0.99591837 1.         0.99180328 0.98770492 0.9795082 ]\n",
            "Mean CV Score: 0.9910 (+/- 0.0141)\n",
            "\n",
            "Validation for recommended_doctor:\n",
            "Cross-validation scores: [0.99591837 1.         0.99180328 0.98770492 0.9795082 ]\n",
            "Mean CV Score: 0.9910 (+/- 0.0141)\n",
            "\n",
            "Feature Importance for stroke_type:\n",
            "                           feature  importance\n",
            "18     smoking_status_never smoked    0.198635\n",
            "21                      trauma_Yes    0.100859\n",
            "7                   hypertension_1    0.097643\n",
            "20                       trauma_No    0.090551\n",
            "23              medication_use_Yes    0.078277\n",
            "22               medication_use_No    0.076316\n",
            "17  smoking_status_formerly smoked    0.066367\n",
            "6                   hypertension_0    0.057694\n",
            "3                symptoms_duration    0.049630\n",
            "19           smoking_status_smokes    0.038613\n",
            "\n",
            "Feature Importance for stroke_stage:\n",
            "                        feature  importance\n",
            "1             avg_glucose_level    0.223768\n",
            "2                           bmi    0.157112\n",
            "8               heart_disease_0    0.097666\n",
            "6                hypertension_0    0.088516\n",
            "9               heart_disease_1    0.084829\n",
            "0                           age    0.082841\n",
            "7                hypertension_1    0.076915\n",
            "18  smoking_status_never smoked    0.020561\n",
            "15         Residence_type_Rural    0.017605\n",
            "16         Residence_type_Urban    0.016810\n",
            "\n",
            "Feature Importance for medication:\n",
            "                        feature  importance\n",
            "1             avg_glucose_level    0.223768\n",
            "2                           bmi    0.157112\n",
            "8               heart_disease_0    0.097666\n",
            "6                hypertension_0    0.088516\n",
            "9               heart_disease_1    0.084829\n",
            "0                           age    0.082841\n",
            "7                hypertension_1    0.076915\n",
            "18  smoking_status_never smoked    0.020561\n",
            "15         Residence_type_Rural    0.017605\n",
            "16         Residence_type_Urban    0.016810\n",
            "\n",
            "Feature Importance for recommended_duration:\n",
            "                        feature  importance\n",
            "1             avg_glucose_level    0.223768\n",
            "2                           bmi    0.157112\n",
            "8               heart_disease_0    0.097666\n",
            "6                hypertension_0    0.088516\n",
            "9               heart_disease_1    0.084829\n",
            "0                           age    0.082841\n",
            "7                hypertension_1    0.076915\n",
            "18  smoking_status_never smoked    0.020561\n",
            "15         Residence_type_Rural    0.017605\n",
            "16         Residence_type_Urban    0.016810\n",
            "\n",
            "Feature Importance for recommended_doctor:\n",
            "                        feature  importance\n",
            "1             avg_glucose_level    0.223768\n",
            "2                           bmi    0.157112\n",
            "8               heart_disease_0    0.097666\n",
            "6                hypertension_0    0.088516\n",
            "9               heart_disease_1    0.084829\n",
            "0                           age    0.082841\n",
            "7                hypertension_1    0.076915\n",
            "18  smoking_status_never smoked    0.020561\n",
            "15         Residence_type_Rural    0.017605\n",
            "16         Residence_type_Urban    0.016810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download CNN model\n",
        "files.download('/content/drive/MyDrive/Recommendations /claude_stroke_recommendation_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cTBpzVPNzAhR",
        "outputId": "6cc19ddf-6740-4a00-9aaf-3feba395a028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_22723425-2945-446f-8791-989c8a542238\", \"claude_stroke_recommendation_model.pkl\", 9557619)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ZVsLlPPgunw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5zcjuJUQtoWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LdasM2R2toPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import classification_report, make_scorer, accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "class StrokeRecommendationModel:\n",
        "    def __init__(self, input_columns, output_columns):\n",
        "        self.input_columns = input_columns\n",
        "        self.output_columns = output_columns\n",
        "        self.label_encoders = {col: LabelEncoder() for col in output_columns}\n",
        "        self.model = None\n",
        "        self.preprocessor = None\n",
        "        self.feature_names = None\n",
        "        self.class_distributions = {}\n",
        "        self.output_mappings = {}\n",
        "\n",
        "    def _validate_inputs(self, X, Y):\n",
        "        if X.shape[0] != Y.shape[0]:\n",
        "            raise ValueError(\"X and Y must have the same number of samples\")\n",
        "\n",
        "        for col in self.output_columns:\n",
        "            unique_values = Y[col].nunique()\n",
        "            if unique_values < 2:\n",
        "                raise ValueError(f\"Output column {col} has insufficient unique values ({unique_values})\")\n",
        "\n",
        "    def _analyze_class_distribution(self, Y):\n",
        "        for col in self.output_columns:\n",
        "            dist = Y[col].value_counts(normalize=True)\n",
        "            self.class_distributions[col] = dist\n",
        "            print(f\"\\nClass distribution for {col}:\")\n",
        "            print(dist)\n",
        "\n",
        "    def create_preprocessing_pipeline(self, X):\n",
        "        # Remove 'trauma' from numerical columns if it's causing issues\n",
        "        numerical_cols = [col for col in X.select_dtypes(include=['int64', 'float64']).columns\n",
        "                         if col in self.input_columns and col != 'trauma']\n",
        "        categorical_cols = [col for col in X.select_dtypes(include=['object']).columns\n",
        "                           if col in self.input_columns]\n",
        "\n",
        "        self.preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', Pipeline([\n",
        "                    ('imputer', SimpleImputer(strategy='median')),\n",
        "                    ('scaler', StandardScaler())\n",
        "                ]), numerical_cols),\n",
        "                ('cat', Pipeline([\n",
        "                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "                    ('onehot', OneHotEncoder(handle_unknown='infrequent_if_exist', max_categories=20))\n",
        "                ]), categorical_cols)\n",
        "            ])\n",
        "\n",
        "        return self.preprocessor\n",
        "\n",
        "    def train(self, X, Y, test_size=0.2, random_state=42):\n",
        "        self._validate_inputs(X, Y)\n",
        "        self._analyze_class_distribution(Y)\n",
        "\n",
        "        # Encode outputs and create mappings\n",
        "        Y_encoded = Y.copy()\n",
        "        for col in self.output_columns:\n",
        "            Y_encoded[col] = self.label_encoders[col].fit_transform(Y[col])\n",
        "            self.output_mappings[col] = {\n",
        "                idx: label for idx, label in enumerate(self.label_encoders[col].classes_)\n",
        "            }\n",
        "\n",
        "        self.create_preprocessing_pipeline(X)\n",
        "\n",
        "        self.model = Pipeline([\n",
        "            ('preprocessor', self.preprocessor),\n",
        "            ('classifier', MultiOutputClassifier(\n",
        "                RandomForestClassifier(\n",
        "                    n_estimators=150,\n",
        "                    class_weight='balanced',\n",
        "                    max_depth=5,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            ))\n",
        "        ])\n",
        "\n",
        "        # Adjusted cross-validation with proper scoring\n",
        "        def multioutput_accuracy(y_true, y_pred):\n",
        "            return np.mean(np.all(y_pred == y_true, axis=1))\n",
        "\n",
        "        cv_scores = cross_val_score(\n",
        "            self.model, X, Y_encoded,\n",
        "            cv=5,\n",
        "            scoring=make_scorer(multioutput_accuracy)\n",
        "        )\n",
        "\n",
        "        print(\"\\nCross-validation results:\")\n",
        "        print(f\"Validation accuracy: {np.mean(cv_scores):.3f} ± {np.std(cv_scores):.3f}\")\n",
        "\n",
        "        # Final training and evaluation\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "            X, Y_encoded,\n",
        "            test_size=test_size,\n",
        "            random_state=random_state\n",
        "        )\n",
        "\n",
        "        self.model.fit(X_train, Y_train)\n",
        "        Y_pred = self.model.predict(X_test)\n",
        "\n",
        "        # Store feature names\n",
        "        self.feature_names = self.model.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "        # Evaluation reports\n",
        "        print(\"\\nTest set evaluation:\")\n",
        "        for i, col in enumerate(self.output_columns):\n",
        "            print(f\"\\nClassification Report for {col}:\")\n",
        "            print(classification_report(Y_test.iloc[:, i], Y_pred[:, i]))\n",
        "\n",
        "    def save_model(self, filename):\n",
        "        model_package = {\n",
        "            'model': self.model,\n",
        "            'label_encoders': self.label_encoders,\n",
        "            'input_columns': self.input_columns,\n",
        "            'output_columns': self.output_columns,\n",
        "            'output_mappings': self.output_mappings,\n",
        "            'feature_names': self.feature_names\n",
        "        }\n",
        "        joblib.dump(model_package, filename)\n",
        "        print(f\"Model saved to {filename}\")\n",
        "\n",
        "def main():\n",
        "    # Updated input columns (remove 'trauma' if not present in data)\n",
        "    input_columns = [\n",
        "        'age', 'gender', 'hypertension', 'heart_disease', 'ever_married',\n",
        "        'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
        "        'smoking_status', 'medication_use', 'symptoms_duration'\n",
        "    ]\n",
        "\n",
        "    output_columns = [\n",
        "        'stroke_type', 'stroke_stage', 'medication',\n",
        "        'recommended_duration', 'recommended_doctor'\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(\"/content/drive/MyDrive/Recommendations /final modified recommendations file.csv\")\n",
        "        print(f\"Data loaded: {df.shape[0]} samples\")\n",
        "\n",
        "        # Ensure data types match Flask expectations\n",
        "        numeric_cols = ['age', 'hypertension', 'heart_disease',\n",
        "                       'avg_glucose_level', 'bmi', 'symptoms_duration']\n",
        "        for col in numeric_cols:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "\n",
        "        categorical_cols = list(set(input_columns) - set(numeric_cols))\n",
        "        for col in categorical_cols:\n",
        "            df[col] = df[col].astype(str).fillna('Unknown')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return\n",
        "\n",
        "    model = StrokeRecommendationModel(input_columns, output_columns)\n",
        "\n",
        "    try:\n",
        "        model.train(df[input_columns], df[output_columns])\n",
        "\n",
        "        # Test prediction with proper output handling\n",
        "        sample_input = pd.DataFrame([{\n",
        "            'age': 45.0,\n",
        "            'gender': 'Male',\n",
        "            'hypertension': 1.0,\n",
        "            'heart_disease': 0.0,\n",
        "            'ever_married': 'Yes',\n",
        "            'work_type': 'Private',\n",
        "            'Residence_type': 'Urban',\n",
        "            'avg_glucose_level': 120.5,\n",
        "            'bmi': 25.5,\n",
        "            'smoking_status': 'Formerly Smoked',\n",
        "            'medication_use': 'No',\n",
        "            'symptoms_duration': 30.0\n",
        "        }])\n",
        "\n",
        "        prediction = model.model.predict(sample_input)\n",
        "        print(\"\\nSample prediction test:\")\n",
        "        for i, col in enumerate(output_columns):\n",
        "            decoded = model.label_encoders[col].inverse_transform([prediction[0][i]])[0]\n",
        "            print(f\"{col}: {decoded}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Training failed: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        model.save_model('/content/drive/MyDrive/Recommendations /claude2_stroke_recommendation_model.pkl')\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7-zgTxvtoDl",
        "outputId": "48c6b06b-cdf4-4f46-fea9-b6a2e46b235a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded: 1222 samples\n",
            "\n",
            "Class distribution for stroke_type:\n",
            "stroke_type\n",
            "Ischemic       0.788871\n",
            "Hemorrhagic    0.190671\n",
            "TIA            0.020458\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution for stroke_stage:\n",
            "stroke_stage\n",
            "Moderate    0.546645\n",
            "Early       0.319967\n",
            "Critical    0.133388\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution for medication:\n",
            "medication\n",
            "Clopidogrel + Blood Thinners       0.546645\n",
            "Aspirin                            0.319967\n",
            "Alteplase + Intensive Care Meds    0.133388\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution for recommended_duration:\n",
            "recommended_duration\n",
            "14    0.546645\n",
            "7     0.319967\n",
            "21    0.133388\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution for recommended_doctor:\n",
            "recommended_doctor\n",
            "Neurologist          0.546645\n",
            "General Physician    0.319967\n",
            "Stroke Specialist    0.133388\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Cross-validation results:\n",
            "Validation accuracy: 0.928 ± 0.010\n",
            "\n",
            "Test set evaluation:\n",
            "\n",
            "Classification Report for stroke_type:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95        40\n",
            "           1       1.00      0.99      0.99       200\n",
            "           2       0.45      1.00      0.62         5\n",
            "\n",
            "    accuracy                           0.98       245\n",
            "   macro avg       0.82      0.96      0.86       245\n",
            "weighted avg       0.99      0.98      0.98       245\n",
            "\n",
            "\n",
            "Classification Report for stroke_stage:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99        36\n",
            "           1       0.95      1.00      0.97        76\n",
            "           2       1.00      0.96      0.98       133\n",
            "\n",
            "    accuracy                           0.98       245\n",
            "   macro avg       0.97      0.99      0.98       245\n",
            "weighted avg       0.98      0.98      0.98       245\n",
            "\n",
            "\n",
            "Classification Report for medication:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99        36\n",
            "           1       0.95      1.00      0.97        76\n",
            "           2       1.00      0.96      0.98       133\n",
            "\n",
            "    accuracy                           0.98       245\n",
            "   macro avg       0.97      0.99      0.98       245\n",
            "weighted avg       0.98      0.98      0.98       245\n",
            "\n",
            "\n",
            "Classification Report for recommended_duration:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97        76\n",
            "           1       1.00      0.96      0.98       133\n",
            "           2       0.97      1.00      0.99        36\n",
            "\n",
            "    accuracy                           0.98       245\n",
            "   macro avg       0.97      0.99      0.98       245\n",
            "weighted avg       0.98      0.98      0.98       245\n",
            "\n",
            "\n",
            "Classification Report for recommended_doctor:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97        76\n",
            "           1       1.00      0.96      0.98       133\n",
            "           2       0.97      1.00      0.99        36\n",
            "\n",
            "    accuracy                           0.98       245\n",
            "   macro avg       0.97      0.99      0.98       245\n",
            "weighted avg       0.98      0.98      0.98       245\n",
            "\n",
            "\n",
            "Sample prediction test:\n",
            "stroke_type: Ischemic\n",
            "stroke_stage: Early\n",
            "medication: Aspirin\n",
            "recommended_duration: 7\n",
            "recommended_doctor: General Physician\n",
            "Model saved to /content/drive/MyDrive/Recommendations /claude2_stroke_recommendation_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bW3w_z3iubKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Recommendations /final modified recommendations file.csv\").drop(columns=['trauma'])\n",
        "df.to_csv(\"Recommendations_clean_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "6zg3zRQk3TTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WHWxu5njo0xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FA1tP04Eo0kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/Recommendations /Recommendations_clean_data.csv')  # Replace with your input CSV filename\n",
        "\n",
        "# Remove decimals by converting to integers\n",
        "df['age'] = df['age'].astype(int)\n",
        "df['avg_glucose_level'] = df['avg_glucose_level'].round().astype(int)\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "df.to_csv('FINAL RECOMMENDATOINS.csv', index=False)"
      ],
      "metadata": {
        "id": "R4jRmXoI3fGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cqHK_eRhpUg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCxz8Rk5p3Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import classification_report, make_scorer, accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "class StrokeRecommendationModel:\n",
        "    def __init__(self, input_columns, output_columns):\n",
        "        self.input_columns = input_columns\n",
        "        self.output_columns = output_columns\n",
        "        self.label_encoders = {col: LabelEncoder() for col in output_columns}\n",
        "        self.model = None\n",
        "        self.preprocessor = None\n",
        "        self.feature_names = None\n",
        "        self.class_distributions = {}\n",
        "        self.output_mappings = {}\n",
        "\n",
        "    def _validate_inputs(self, X, Y):\n",
        "        if X.shape[0] != Y.shape[0]:\n",
        "            raise ValueError(\"X and Y must have the same number of samples\")\n",
        "\n",
        "        for col in self.output_columns:\n",
        "            unique_values = Y[col].nunique()\n",
        "            if unique_values < 2:\n",
        "                raise ValueError(f\"Output column {col} has insufficient unique values ({unique_values})\")\n",
        "\n",
        "    def _analyze_class_distribution(self, Y):\n",
        "        for col in self.output_columns:\n",
        "            dist = Y[col].value_counts(normalize=True)\n",
        "            self.class_distributions[col] = dist\n",
        "            print(f\"\\nClass distribution for {col}:\")\n",
        "            print(dist)\n",
        "\n",
        "    def create_preprocessing_pipeline(self, X):\n",
        "        # Remove 'trauma' from numerical columns if it's causing issues\n",
        "        numerical_cols = [col for col in X.select_dtypes(include=['int64', 'float64']).columns\n",
        "                         if col in self.input_columns and col != 'trauma']\n",
        "        categorical_cols = [col for col in X.select_dtypes(include=['object']).columns\n",
        "                           if col in self.input_columns]\n",
        "\n",
        "        self.preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', Pipeline([\n",
        "                    ('imputer', SimpleImputer(strategy='median')),\n",
        "                    ('scaler', StandardScaler())\n",
        "                ]), numerical_cols),\n",
        "                ('cat', Pipeline([\n",
        "                    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "                    ('onehot', OneHotEncoder(handle_unknown='infrequent_if_exist', max_categories=20))\n",
        "                ]), categorical_cols)\n",
        "            ])\n",
        "\n",
        "        return self.preprocessor\n",
        "\n",
        "    def train(self, X, Y, test_size=0.2, random_state=42):\n",
        "        self._validate_inputs(X, Y)\n",
        "        self._analyze_class_distribution(Y)\n",
        "\n",
        "        # Encode outputs and create mappings\n",
        "        Y_encoded = Y.copy()\n",
        "        for col in self.output_columns:\n",
        "            Y_encoded[col] = self.label_encoders[col].fit_transform(Y[col])\n",
        "            self.output_mappings[col] = {\n",
        "                idx: label for idx, label in enumerate(self.label_encoders[col].classes_)\n",
        "            }\n",
        "\n",
        "        self.create_preprocessing_pipeline(X)\n",
        "\n",
        "        self.model = Pipeline([\n",
        "            ('preprocessor', self.preprocessor),\n",
        "            ('classifier', MultiOutputClassifier(\n",
        "                RandomForestClassifier(\n",
        "                    n_estimators=150,\n",
        "                    class_weight='balanced',\n",
        "                    max_depth=5,\n",
        "                    random_state=random_state\n",
        "                )\n",
        "            ))\n",
        "        ])\n",
        "\n",
        "        # Adjusted cross-validation with proper scoring\n",
        "        def multioutput_accuracy(y_true, y_pred):\n",
        "            return np.mean(np.all(y_pred == y_true, axis=1))\n",
        "\n",
        "        cv_scores = cross_val_score(\n",
        "            self.model, X, Y_encoded,\n",
        "            cv=5,\n",
        "            scoring=make_scorer(multioutput_accuracy)\n",
        "        )\n",
        "\n",
        "        print(\"\\nCross-validation results:\")\n",
        "        print(f\"Validation accuracy: {np.mean(cv_scores):.3f} ± {np.std(cv_scores):.3f}\")\n",
        "\n",
        "        # Final training and evaluation\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "            X, Y_encoded,\n",
        "            test_size=test_size,\n",
        "            random_state=random_state\n",
        "        )\n",
        "\n",
        "        self.model.fit(X_train, Y_train)\n",
        "        Y_pred = self.model.predict(X_test)\n",
        "\n",
        "        # Store feature names\n",
        "        self.feature_names = self.model.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "        # Evaluation reports\n",
        "        print(\"\\nTest set evaluation:\")\n",
        "        for i, col in enumerate(self.output_columns):\n",
        "            print(f\"\\nClassification Report for {col}:\")\n",
        "            print(classification_report(Y_test.iloc[:, i], Y_pred[:, i]))\n",
        "\n",
        "    def save_model(self, filename):\n",
        "        model_package = {\n",
        "            'model': self.model,\n",
        "            'label_encoders': self.label_encoders,\n",
        "            'input_columns': self.input_columns,\n",
        "            'output_columns': self.output_columns,\n",
        "            'output_mappings': self.output_mappings,\n",
        "            'feature_names': self.feature_names\n",
        "        }\n",
        "        joblib.dump(model_package, filename)\n",
        "        print(f\"Model saved to {filename}\")\n",
        "\n",
        "def main():\n",
        "    # Updated input columns (remove 'trauma' if not present in data)\n",
        "    input_columns = [\n",
        "        'age', 'gender', 'hypertension', 'heart_disease', 'ever_married',\n",
        "        'work_type', 'Residence_type', 'avg_glucose_level', 'bmi',\n",
        "        'smoking_status', 'medication_use', 'symptoms_duration'\n",
        "    ]\n",
        "\n",
        "    output_columns = [\n",
        "        'stroke_type', 'stroke_stage', 'medication',\n",
        "        'recommended_duration', 'recommended_doctor'\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(\"/content/drive/MyDrive/Recommendations /FINAL RECOMMENDATOINS.csv\")\n",
        "        print(f\"Data loaded: {df.shape[0]} samples\")\n",
        "\n",
        "        # Ensure data types match Flask expectations\n",
        "        numeric_cols = ['age', 'hypertension', 'heart_disease',\n",
        "                       'avg_glucose_level', 'bmi', 'symptoms_duration']\n",
        "        for col in numeric_cols:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "\n",
        "        categorical_cols = list(set(input_columns) - set(numeric_cols))\n",
        "        for col in categorical_cols:\n",
        "            df[col] = df[col].astype(str).fillna('Unknown')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return\n",
        "\n",
        "    model = StrokeRecommendationModel(input_columns, output_columns)\n",
        "\n",
        "    try:\n",
        "        model.train(df[input_columns], df[output_columns])\n",
        "\n",
        "        # Test prediction with proper output handling\n",
        "        sample_input = pd.DataFrame([{\n",
        "            'age': 45.0,\n",
        "            'gender': 'Male',\n",
        "            'hypertension': 1.0,\n",
        "            'heart_disease': 0.0,\n",
        "            'ever_married': 'Yes',\n",
        "            'work_type': 'Private',\n",
        "            'Residence_type': 'Urban',\n",
        "            'avg_glucose_level': 120.5,\n",
        "            'bmi': 25.5,\n",
        "            'smoking_status': 'Formerly Smoked',\n",
        "            'medication_use': 'No',\n",
        "            'symptoms_duration': 30.0\n",
        "        }])\n",
        "\n",
        "        prediction = model.model.predict(sample_input)\n",
        "        print(\"\\nSample prediction test:\")\n",
        "        for i, col in enumerate(output_columns):\n",
        "            decoded = model.label_encoders[col].inverse_transform([prediction[0][i]])[0]\n",
        "            print(f\"{col}: {decoded}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Training failed: {e}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        model.save_model('/content/drive/MyDrive/Recommendations /CLAUDE_RECOMMENDATOIN_MODEL')\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq2z-2GMp225",
        "outputId": "eb55c7d7-6890-4ed3-c853-93577505bff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded: 1222 samples\n",
            "\n",
            "Class distribution for stroke_type:\n",
            "stroke_type\n",
            "Ischemic       0.788871\n",
            "Hemorrhagic    0.190671\n",
            "TIA            0.020458\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution for stroke_stage:\n",
            "stroke_stage\n",
            "Moderate    0.546645\n",
            "Early       0.319967\n",
            "Critical    0.133388\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution for medication:\n",
            "medication\n",
            "Clopidogrel + Blood Thinners       0.546645\n",
            "Aspirin                            0.319967\n",
            "Alteplase + Intensive Care Meds    0.133388\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution for recommended_duration:\n",
            "recommended_duration\n",
            "14    0.546645\n",
            "7     0.319967\n",
            "21    0.133388\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Class distribution for recommended_doctor:\n",
            "recommended_doctor\n",
            "Neurologist          0.546645\n",
            "General Physician    0.319967\n",
            "Stroke Specialist    0.133388\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Cross-validation results:\n",
            "Validation accuracy: 0.930 ± 0.014\n",
            "\n",
            "Test set evaluation:\n",
            "\n",
            "Classification Report for stroke_type:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.90      0.95        40\n",
            "           1       1.00      0.99      0.99       200\n",
            "           2       0.45      1.00      0.62         5\n",
            "\n",
            "    accuracy                           0.98       245\n",
            "   macro avg       0.82      0.96      0.86       245\n",
            "weighted avg       0.99      0.98      0.98       245\n",
            "\n",
            "\n",
            "Classification Report for stroke_stage:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99        36\n",
            "           1       0.94      1.00      0.97        76\n",
            "           2       1.00      0.95      0.98       133\n",
            "\n",
            "    accuracy                           0.98       245\n",
            "   macro avg       0.97      0.98      0.98       245\n",
            "weighted avg       0.98      0.98      0.98       245\n",
            "\n",
            "\n",
            "Classification Report for medication:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99        36\n",
            "           1       0.94      1.00      0.97        76\n",
            "           2       1.00      0.95      0.98       133\n",
            "\n",
            "    accuracy                           0.98       245\n",
            "   macro avg       0.97      0.98      0.98       245\n",
            "weighted avg       0.98      0.98      0.98       245\n",
            "\n",
            "\n",
            "Classification Report for recommended_duration:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97        76\n",
            "           1       1.00      0.95      0.98       133\n",
            "           2       0.97      1.00      0.99        36\n",
            "\n",
            "    accuracy                           0.98       245\n",
            "   macro avg       0.97      0.98      0.98       245\n",
            "weighted avg       0.98      0.98      0.98       245\n",
            "\n",
            "\n",
            "Classification Report for recommended_doctor:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97        76\n",
            "           1       1.00      0.95      0.98       133\n",
            "           2       0.97      1.00      0.99        36\n",
            "\n",
            "    accuracy                           0.98       245\n",
            "   macro avg       0.97      0.98      0.98       245\n",
            "weighted avg       0.98      0.98      0.98       245\n",
            "\n",
            "\n",
            "Sample prediction test:\n",
            "stroke_type: Ischemic\n",
            "stroke_stage: Early\n",
            "medication: Aspirin\n",
            "recommended_duration: 7\n",
            "recommended_doctor: General Physician\n",
            "Model saved to /content/drive/MyDrive/Recommendations /CLAUDE_RECOMMENDATOIN_MODEL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download CNN model\n",
        "files.download('/content/drive/MyDrive/Recommendations /CLAUDE_RECOMMENDATOIN_MODEL')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xADARiz9p-_X",
        "outputId": "a68983f1-8b6a-4517-a2f3-0937ddd4eb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e9c59319-d8e0-4882-a931-d65c0ca0c5e5\", \"CLAUDE_RECOMMENDATOIN_MODEL\", 3497547)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EytiSTQ-qS-Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}